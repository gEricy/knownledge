

# 前言

\ \ \ \ 写在最前，本文主要以知识框架为主，根据自己对知识掌握的情况，进行知识点的梳理（有的知识点实际上篇幅很大，但是由于自己理解，就没有详细叙述）。

---

*select* [ALL\|DISTANCE] \<目标列表达式\> *from* \<表名或视图名\> where \<条件表达式\> group by \<列名\> having \<条件表达式\> order by \<列名\> ASC\|DESC

- 书写顺序：select...from...where...group by...having...order by.. 

- 执行顺序：from...where...group by...having...select...order by...

SELECT * FROM press AS p INNER JOIN authors AS a ON p.city=a.city 

# SQL关系型数据库

# 1. 索引

## 1.1. 索引是什么？

加快SQL查询速度的数据结构，引来的缺点（降低更新表的速度，保存索引占用空间）

## 1.2. 索引采用那些数据结构？

1. HASH索引：底层是[哈希表](https://github.com/gEricy/knownledge/blob/master/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%93%88%E5%B8%8C%E8%A1%A8.md)，存储KV，在进行查找时，O(1)就可以找到相应的键值
2. B+Tree索引：[B+树](https://github.com/gEricy/knownledge/blob/master/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/B%2BTree.md)，多路平衡查找树，每次查询都是从根节点出发，查找到叶子节点就可以获得所查的值
   - MySQL中的数据一般是放在磁盘中的，读取数据的时候肯定会有访问磁盘的操作， B+Tree是专门为磁盘IO设计的一种多路平衡查找树，它的高度远远小于其他数据结构，因此访问磁盘的数量极小，磁盘IO所花的时间少。
   - B+树为什么比B树更适合？
     - 1）B+树的内部节点不存放数据，只有叶子节点存放数据 ==> 其内部节点相对B树更小
     - 2）B+树的叶子节点形成链表，便于范围查询
     - 3）B+树的查询效率更加稳定：B+树的数据都存储在叶子结点中，所以任何关键字的查找必须走一条从根结点到叶子结点的路，所有关键字查询的路径长度相同，导致每一个数据的查询效率相当

### 1.2.1. HASH索引和B+Tree索引对比

1. HASH索引等值查询更快O(1)，但是不支持采用key排序/范围查询/最左匹配原则/模糊查询

2. HASH函数选择不好时，会发生HASH碰撞，导致查询效率降低

3. HASH索引任何时候都避免不了回表查询，B+索引在覆盖查询时，可以避免回表查询

4. HASH索引是存放在内存中的，占用内存资源太大

### 1.2.2. 为什么底层使用B+Tree，不使用二叉树、BST、AVL、RBT

这个知识点很基本，就不详细阐述了，这是由数据结构的时间复杂度决定的，二叉树/BST会退化成链表、AVL树旋转代价太高、RBT树太高

## 1.3. 索引种类

1. 普通索引：最基本的索引，没有任何限制

2. 唯一索引：不允许具有索引值相同的行，从而禁止重复索引或键值，“唯一”：假如在name上建立唯一索引，那么，整个表就不能有两个行name相同的情况

   - 问题：唯一索引允许为NULL么？出现NULL会造成什么影响？
     - 答：允许为NULL。NULL表示的是未知，因此两个NULL比较的结果既不相等，也不不等，所以结果仍然是未知

3. 组合索引：又叫联合索引，一个索引包含多个列。:slightly_smiling_face:<u>（最左匹配原则）</u>

4. 全文索引：FULLTEXT，它是通过关键字语义匹配分析方式来进行过滤查询，仅适用于MYISAM引擎的数据表

   ---

   :smile: 下面介绍的索引，并不是一种单独的索引类型，而是索引的特殊实现

   - 聚簇索引/非聚簇索引：数据存储方式不同
   - 全文索引：语法词法分析，NLP
   - 覆盖索引：优化索引，防止回表查询的手段

### 1.3.1. 聚簇/主键索引、非聚簇/非主键索引

聚簇索引、非聚簇索引，并不是一种索引类型，而是一种数据存储方式。

#### :question:**​：二者的核心区别**

答：索引的位置存放的是真实数据？还是主键值？（① 主键索引的叶子节点存放的是要查找的真实数据，主键索引也被称为聚簇索引。② 非聚簇索引的叶子节点存放的不是真实的数据，而是**主键值**，它也被称为二级索引）

- 聚簇索引：索引B+Tree的叶子节点上存放了数据行的物理地址

- 非聚簇索引：非聚簇索引B+Tree树的叶子节点存储的不再是行的物理位置，而是主键值；索引数据时，需要两次查询（通过非聚簇索引查找到主键值，再通过主键值在主键索引中查找到该主键对应的真实数据）

#### :clinking_glasses: 二者的查询方式案例，并引出什么是“**回表**”！

1. 如果查询语句是select \* from table where ID=100，即主键查询方式，则只需要搜索ID=100的B+树的叶子节点
2. 如果查询语句是select \* from table where score=30，即非主键查询方式，则先通过非聚簇索引查找score=30的主键索引（即ID索引），再经过主键索引搜索一次才查找到数据行。这个操作也被称之为回表查询。

可以看到， 聚簇索引查询速度一般更快，因为它不需要二级/多级查询

---

#### **:question:：可以存在多个聚簇索引么？**

答：聚簇索引的顺序就是数据的物理存储顺序，正式因为如此，所以一个表最多只能有一个聚簇索引。

---

#### :green_heart: innodb主键自增索引

参考链接: [为什么选用自增量作为主键索引](https://blog.csdn.net/mingwulipo/article/details/87898706)，[[InnoDB中没有主键是如何运转的](https://www.cnblogs.com/luyuqiang/p/innodb-no-primary-key.html)，总结下个人理解。

myisam存储引擎的B+Tree的索引叶子节点data域，存放的是（数据记录的地址）

innodb存储引擎的B+Tree的索引叶子节点data域，存放的是（主键值）

- **为什么innodb插入时，一般按照主键增加的方式？**

  答：这与索引的B+树数据结构有关。innodb的主键索引上存放的是主键值，采用递增的方式向B+Tree中插入数据，可以最少的降低B+Tree分裂合并次数。如果采用乱序插入，创建B+Tree的过程性能就比较低下了。

- **如果innodb没有主键，会发生什么？**

  先说结论：每个InnoDB引擎的表必须有一个“聚簇索引”

  答：如果InnoDB引擎的表没有主键or没有不为NULL的唯一索引，innodb内部会合成一个隐藏的聚簇/主键索引，该索引一般采用行ID，它是<u>6个字节（48bit）</u>的。

### 1.3.2. 覆盖索引

:question:：**上面提到了非聚簇索引的回表查询，会查找主键索引，进而查到数据，那么，请问：所有的非聚簇索引都一定会经过回表查询么？**

答：不是，覆盖索引解决了该问题。

覆盖索引：当sql语句的所求查询字段（select列）和查询条件字段（where子句属性列）全都包含在一个索引中，就可以直接使用索引查询而不需要回表！

:question:： **怎么通过覆盖索引优化回表查询？**

答：建立联合索引，使要查找的列都在索引中，避免回表查询。即：select （查找项） from where （条件项），查找项 in 条件项 && 查找项 == 索引

### 1.3.3. 全文索引

:cry: 区别：全文索引、模糊匹配like%

- 二者有本质的区别
- 全文索引是以语法分析的方式来分词的，而like是带通配符的匹配
- 使用场景：全文索引（如，可以对特定词的同义词形式来进行查询，一般用于电子商务网站），like模糊匹配（由常规字符串和通配符组成，要符合匹配准则）



### 1.3.4. 索引下推

英文：Index Condition PushDown

select \* from where name like 'zhang%' and age\>18

因为是select \* ，所以一定会触发回表查询，以下有2种查法

1. 查找zhang开头的主键，然后回表查询所有的记录，再过滤age\>18的行

2. 查找zhang开头的数据，再筛选出age\>18的记录，再回表查询所有数据

优化器会选择第2中，因为2先通过两个条件过滤会得到更少的信息，再回表查询



## 1.4. 优化索引口诀 

- 全值匹配我最爱，最左前缀要遵守 

- 带头大哥不能丢，中间兄弟不能断

-  索引列上少计算，范围之后全失效 

- like百分写最右， 覆盖索引不写\*

- 不等空值还有or，索引失效要少用 

- var引号不能丢，SQL高级也不难

---

下面，列出的几条，就是上面口诀的具体展现

1. 查询频率高的列、经常需要排序、分组、联合的字段建立索引

2. 创建索引的数目不宜过多，过多会占用空间，且影响表的更新速度

3. 选择唯一性索引（如学生的学号）

4. 不在索引上做运算符操作

5. 范围条件放最后：因为范围条件后的索引都会失效

6. 字符类型要加双引号

7. or替换为union：A or B，如果A建立了索引，B没有建立索引，则索引通通不走

8. like查询要当心：like %keyword索引失效，like keyword%索引有效

9. 不等于!=要慎用：索引失效

10. 考虑在where或order by 或 group by涉及的列建立索引

# 2. 存储引擎 innodb/myisam

## 2.1. 区别

 innodb/myisam最主要的差别：Innodb 支持事务处理与外键和行级锁，而MyISAM不支持

|              |                            InnoDB                            |                         myisam                          |
| :----------: | :----------------------------------------------------------: | :-----------------------------------------------------: |
|     事务     |                     支持（可靠性要求高）                     |                       不支持事务                        |
|    锁级别    |                  行锁（适用于表更新较频繁）                  |           表锁（适用于查询多，插入和删除少）            |
| 是否支持外键 |                             支持                             |                                                         |
|     查询     |                                                              |                          更快                           |
|   全文索引   |                                                              |                          支持                           |
|   适用场景   | (1)可靠性要求比较高，或者要求事务<br/>(2)表更新和查询都相当的频繁，并且行锁定的机会比较大的情况 | (1) 做很多count 的计算<br/>(2) 查询非常频繁，插入不频繁 |
1. innodb支持事务、外键、行锁(默认)/表锁，不支持全文索引

2. innodb必须有主键，没有显示指定主键，mysql会默认创建主键_rowid；而myisam可以没有主键

3. innodb是主键索引/聚集索引，myisam是非主键索引/非聚集索引。

4. 存储文件

	innodb：frm表结构文件、ibd数据文件(包括索引/数据)

	Myisam：frm表结构文件、MYD数据文件、MYI索引文件



## 2.3. 扩展问题/知识点

### 2.3.1. InnoDB为什么推荐使用自增ID作为主键，不用UUID？

 B+Tree底层结构：在插入的时候，(1)自增ID可以保证每次插入时B+索引是从右边扩展的(2)UUID是随机生成的，不一定key值就比之前的数大，会导致B+树和频繁合并和分裂。 另外，UUID占用16个字节，占用内存较大 


### 2.3.2. innodb无索引or索引失效时，行锁会升级为表锁

# 3. 三范式 :smile:

出现原因：数据冗余、插入/删除/更新异常

第一范式：属性列不可拆分（保证属性列的原子性）

第二范式：消除了非主属性部分依赖于候选码

- （sno,cno,姓名,score,系名,系主任）

  - 候选码是（sno,cno）

  - “姓名”部分依赖于“sno”，因此不满足2NF，应该拆表，即（sno,姓名,系名,系主任）+（sno,cno,score）

第三范式：消除了非主属性传递依赖于候选码
- （sno,姓名,系名,系主任）
  - 候选码是（sno）
  - “系主任”依赖于“系名”（非候选码），“系名”依赖于“sno”（候选码），那么，“系主任”（非主属性）传递依赖于“sno”（候选码），不符合3NF，应该拆表，即：（sno,姓名,系名）+（系名,系主任）

# 4. 事务 :kissing_smiling_eyes:

引出事务的原因：多用户/多程序/多线程，存在同时对表中一个元组进行DML操作，如果不进行控制，就会造成数据不一致性

## 4.1. 特性：ACID

原子性：最小单元，整个事务的所有操作要么做，要么都不做

一致性：从一种一致性状态转换为另一种一致性状态，事务开始/结束都保证完整性

隔离性：并发执行的各个事务之间不相互干扰

持久性：事务一旦提交，结果将永久保存在数据库中

## 4.2. 事务并发问题 :basketball:

**賍读(读取未提交数据)**：B修改某个数据后，未提交，被A读到；之后B回滚修改数据操作，A之前读到的数据就是脏数据

**不可重复读(在一个事务中前后读取的数据不一致)**：A读取同一个数据经历的时间很长，第一次读时，该数据为Val1，之后，该数据被B修改，之后A再去读该数据，结果为Val2，这就叫做不可重复读

**幻读(前后多次读取，数据总量不一致)**：与不可重复读类似，都是在一个事务中，两次读取结果不一样。区别在于幻读是在一个事务中读取到数据的条数不一致，如：事务A在执行读取操作，需要两次统计数据的总量，前一次查询数据总量后，此时事务B执行了新增数据的操作并提交后，这个时候事务A读取的数据总量和之前统计的不一样，就像产生了幻觉一样，平白无故的多了几条数据，称为幻读

## 4.3. 四种隔离级别 :basketball:

**读未提交**：所有事务都能够读取其他事务未提交的数据，会导致賍读、不可重复读、幻读

**读已提交**：所有事务只能读取其他事务已经提交的数据，可以解决賍读！但是会出现在一个事务中前后读取内容不一致的问题，即不可重复读、幻读

**可重复读**：在一个事务中，不允许Update操作，允许Add操作，因此能保证在一个事务中读取数据内容是一致的(能解决不可重复读)，但是不能保证读取到数据条目数一致(会发生幻读)

**可串行化**：所有的事务都顺序串行执行，不存在冲突

---

:slightly_smiling_face:innodb默认隔离级别不是最高的，而是倒数第二高的，即<u>可重复读级别</u>

## 4.4. 事务原理

### 4.4.1. 事务日志redo/undo

之前已经说过，innodb支持事务，它具有事务日志redo/undo，而myisam不支持事务，它没有这两种事务日志。

- **redo log 重做日志，保证事务持久性**
  
  > 保证：所有已经提交的事务的数据仍然存在
  
  - redo_log作用：用于记录事务的变化，记录的是数据修改之后的值，不管事务是否提交都会记录。如果某时刻系统宕机，重启后，可以通过redo log恢复之前的数据
  - 数据库宕机恢复过程：先从redo log中把未落盘的脏页数据恢复回来，重新写入磁盘，保证用户数据不丢失
  - redo_log写入磁盘过程：先写入redo log buffer（redo log缓存） 之后调用fsync，刷新写入redo log物理磁盘（它的写入是可进行参数配置的）
  
- **undo log 回滚日志，保证事务原子性**
  
  > 保证：所有没有提交的事务的数据自动回滚
  
  - 数据更新时，会写入undo log（该操作和数据更新执行操作相反，即如果是插入数据，则undo log是删除数据）
  - 回滚：当事务失败或回滚时，根据undo log，把未提交的事务回滚到更新前的状态

----

- 为什么要有Binlog

  > 不管SQL使用那种存储引擎，都有Binlog，它是Server层的（而redo log是innodb层的）

- SQL引入二阶段提交，保证主从数据的一致性！

  > SQL会为每一个事务，分配一个事务ID（XID）
  >
  > commit被分为2个节点：papare/commit
  >
  > Binlog会被仿作事务协调者

  - ① 准备阶段（papare）

    > - 此时SQL已经成功执行，生成XID信息以及Redo/Undo的内存日志
    >
    > - 然后调用papare方法，将事务状态设置为TRX_PREPARED，并将Redo log刷入磁盘

  - ② 提交阶段（commit）

    > （1）提交 or 回滚
    >
    > - 如果事务设计的所有存储引擎的papare都执行成功，则将SQL语句写入Binlog，调用fsync写入磁盘
    > - 如果事务设计的所有存储引擎的papare都执行失败，则SQL语句不会写入Binlog，此时事务回滚
    >
    > （2）告诉引擎进行commit
    >
    > - （假设papare成功，完成事务提交）会清除undo信息，调用fsync刷redo日志到磁盘，将事务设置为TRX_NOT_STARTED状态

  - 由上面的二阶段提交流程可以看出

    > 一旦步骤②中的操作完成，就确保了事务的提交。此外需要注意的是，每个步骤都需要进行一次fsync操作才能保证上下两层数据的一致性。步骤2的fsync参数由sync_binlog=1控制，步骤3的fsync由参数innodb_flush_log_at_trx_commit=1控制，俗称“双1”，是保证CrashSafe的根本。

---

:slightly_smiling_face: 双1、组提交

---



### 4.4.2. 二进制日志Binlog

binlog与redo log类似，它记录了对数据库执行更新的所有操作，但是二者还是有本质的区别

binlog - 主要用作主从复制和即时点恢复



|          |                         redo log                         |                          binlog                           |
| :------: | :------------------------------------------------------: | :-------------------------------------------------------: |
|   场景   |    crash-recovery宕机恢复（保证事务持久性），事务安全    | point-time-recovery恢复某个时间点（即使点恢复）；主从复制 |
|   层次   |        只有innodb支持事务的存储引擎有（innodb层）        |                 所有SQL都支持（Server层）                 |
| 写入时机 | 在事务进行中不断地写入，并日志不是随事务提交而顺序写入的 |               只在事务完成后，进行一次写入                |
|   功能   |                      保证事务一致性                      |            记录数据库DML操作，能够实现主从复制            |

# 5. 锁

当数据库有并发事务时，可能会产生数据不一致，锁可以保证访问次序。

## 5.1. 共享锁（读锁）/ 独占锁（写锁）

（1）共享锁(读锁)：可以被多个事务同时读，但是加了读锁，不允许加写锁

（2）独占锁(写锁)：加了写锁，不允许加读锁or写锁

## 5.2. 乐观锁 / 悲观锁

（1）乐观锁：MySql最经常使用的乐观锁是进行**version版本控制**（在[分布式锁](https://github.com/gEricy/knownledge/blob/master/X_%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81.md)中，讲到过SQL的乐观锁/幂等），也就是在数据库表中增加一列，记为version。

- ① 当将数据读出时，将版本号一并读出；当数据进行更新时，会对这个版本号进行加1；
- ② 当提交数据时，会判断数据库表中当前的version列值和当时读出的version是否相同；
- ③ 若相同，说明没有进行更新的操作，不然，则取消这次的操作。

（2）悲观锁：只允许一个锁进入

## 5.3. 表锁 / 行锁

## 5.4. 多版本并发控制MVCC :slightly_smiling_face:



# 6. SQL优化 :kissing_smiling_eyes:

## 6.1. 单机优化 explain

### 1. 慢查询

(1) 慢查询配置：slow_query_log、slow_query_log_file、long_query_time

(2) 慢查询日志分析工具mysqldumpslow：捕获前10条查询较慢的 mysqldumpslow -s at -t
5 xxx.log

### 2. SQL语句优化

消除子查询，改为关联查询

### 3. 没建立索引，就建立索引

### 4. 对于已经建立的索引，可能存在索引失效

explain查看SQL语句的执行计划：possibe_key, key, key_len，分别表示可能使用的索引，实际使用的索引，使用索引的总字节数，using
index(覆盖索引)/where(回表)/filesort(order by)/temporary(group by 临时表)

| Using字段 |                                                              |
| :-------: | ------------------------------------------------------------ |
|   where   | 回表查询                                                     |
|   index   | 覆盖索引，直接通过索引就可以获取到所有要查询的数据，无需回表查询 |
| filesort  | 并不是说通过磁盘文件进行排序，而只是告诉我们进行了一个排序操作而已(只有在order by 数据列的时候才可能会出现using filesort)  (1)修改逻辑，不在mysql中使用order by而是在应用中自己进行排序  (2)使用mysql索引，将待排序的内容放到索引中，直接利用索引的排序 |
| temporary | group by 临时表                                              |

### 5. 数据插入优化

- 插入前，禁用索引

- 修改事务的提交方式（变多次提交为一次提交）

  ```sql
  插入前，禁用索引
  
  insert into test values(1,2); 
  insert into test values(1,3); 
  insert into test values(1,4); 
  
  insert into test values(1,2),(1,3),(1,4)  //合并多条为一条 
  
  插入后，不禁用索引
  ```

   

## 6.2. 集群优化

### 1. SQL/Redis主从复制

**定义**：将一台主服务器的数据，同步复制到从服务器（数据的复制是单向的，只能由主节点到从节点）

**作用**：① 数据冗余：从节点保存了和主节点一样的数据。 ② 故障恢复：主节点出现问题时，从节点可以提供服务，实现故障恢复。 ③ 负载均衡：在主从复制的基础上，配合读写分离，主节点提供写服务，从节点提供读服务 ④ 高可用基石：哨兵、集群实现高可用

---

上面已经知道，数据库的DML操作，都会保存在binlog中；那么，如何将主节点的binlog同步到各个从节点上呢？原理图见下。

![主从复制原理图](https://github.com/gEricy/knownledge/blob/master/A_%E6%95%B0%E6%8D%AE%E5%BA%93_SQL_Redis/%E5%8E%9F%E7%90%86%E5%9B%BE/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%8E%9F%E7%90%86.png)

① 从数据库开启IO线程，主动拉取binlog，保存为中继日志Relay log 

② 从数据库开启SQL线程，将中继日志Relay log在从服务器上重新执行（执行完成后，主从数据库数据一致）

#### 1.1. 主从复制中延迟问题

**延迟问题产生原因**：从服务器的两个线程执行速度不一致，可能会造成延迟问题。 

① IO线程从主服务器读取日志速度很快（顺序读），而SQL线程重放SQL速度慢，这就会造成从服务器同步数据远远落后于主服务器，导致从服务器数据远远落后于主服务器，（主从数据库长期处于不一致的状态），这种现象就是延迟更新。

（主库经常会开多个线程去写，从库只有一个线程在工作，导致从库效率 \<\< 主库效率）。

**解决方案**：（MTS） 从服务器的数据重放过程采用多线程

![MTS](https://github.com/gEricy/knownledge/blob/master/A_%E6%95%B0%E6%8D%AE%E5%BA%93_SQL_Redis/%E5%8E%9F%E7%90%86%E5%9B%BE/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%BB%B6%E8%BF%9F%E6%9B%B4%E6%96%B0%E4%B9%8BMTS.png)

MTS：要遵循两个规则

① 同一个事务中的MDL，必须分发到同一个worker线程

② MDL同一行的多个事务，必须分发到同一个worker

### 2. 读写分离

|      | 主库只进行更新写操作，从库进行查询读操作     |
|------|----------------------------------------------|
| 主库 | 增删改更新操作，即：更新操作，一直在主服务器 |
| 从库 | 查询操作，即：查询操作，一直在从服务器       |

### 3. 分库分表（水平/垂直）

为什么要进行分库分表？

答：随着公司业务的发展，数据库中的数据量猛增，访问性能也变慢了，优化迫在眉睫。当数据达到100W或100G后，由于查询的维度较多，即使添加从库、优化索引，很多操作仍然性能下降很大。 分库分表是为了解决数据量过大导致数据库性能降低的问题！将原来独立的数据库、表，拆分成多个数据库、表，使得单个数据库、表的数据量变小，从而达到性能优化的目的。

- 垂直分表：将表按照属性列划分成多个表
- 水平分表：数据量行数过大时，按照行分成多个表
- 垂直分库：按照业务将表分不到不同的数据库，每个库可以放在不同的服务器
- 水平分库

## 6.3. 缓存[redis](https://github.com/gEricy/knownledge/blob/master/A_%E6%95%B0%E6%8D%AE%E5%BA%93_SQL_Redis/Redis.md)

防止每次请求都发到数据库上，使用缓存，降低连接数据库操作、数据库处理操作次数，提高数据库性能 



# 7. 分页查询 limit

## 7.1. 原理

limit语法支持两个参数，offset/limit

- offset：从偏移量开始查找
- limit：返回limit条元组

```SQL
## 返回符合条件的第11-20条数据
select * from user limit 10,20
```

本质：limit 10000,10的语法，实际上是mysql查找到前10010条数据，之后丢弃前面的10000行，返回10行数据。（可以看到，查找的前10000行数据是十分消耗资源且没有必要的）

## 7.2. 优化

### 7.2.1. 用id优化

先找到上次分页的最大id

然后利用id上的索引来查询

- 类似于：select \* from user where id >1000000 limit 100.

这样的效率非常快，因为主键上是有索引的；但是这样有个缺点，就是ID必须是连续的，并且查询不能有where语句，因为where语句会造成过滤数据。

### 7.2.2. 用覆盖索引优化

```sql
select * from (select id from job limit 1000000,100) a left join job b on a.id = b.id;
```

先查出索引id，然后根据id查询数据

# 8. 关联查询 join :smile_cat:

- 自身连接

  select FIRST.Cno,SECOND.Cpon   form course FIRST, course SECOND \#重命名 where FIRST.Cpon=SECOND.Cno

- 左连接/右连接

  from A left join B on (连接条件)    \#以A的行为主行,B没有的补NULL from A right join B on (连接条件) \#以B的行为主行,A没有的补NULL

- 内连接

  from A inner join B on (连接条件)    \#A和B的交集

# 9. 存储过程

定义：多个SQL语句的集合，就像是函数，但是它没返回值

优点：一次连接，执行存储过程中所有的SQL语句，效率高

1. 只在创建时编译一次，之后不编译；可以重复使用，提高开发效率
2. 安全性高：可以设定某个用户是否具有某个存储过程的使用权限

```sql
create procedure insert_student_process(name varchar(50),age int,out_id ing) //创建存储过程
begin:
insert into student value(null,name,age)
select max(stuId) into id from studentend;
call insert_student_process('Jamed',26,\@id); //调用存储过程select \@id;
```

# 10. 触发器

触发器：需要有触发条件，当条件满足以后做什么操作

例如1：校内网，开心网，facebook，你发一个日志，自动通知好友，其实就是增加日志时做的一个后触发，再向"通知表"写入条目。==> 触发器的效率高

# 11. 思考

## 11.1. select \* 与 select全部字段

|                      |  **select \***   | **select 全部字段** |
| :------------------: | :--------------: | :-----------------: |
| 是否需要解析数据字典 |        是        |         否          |
|     结果输出顺序     | 与建表列顺序相同 |   按指定字段顺序    |
|      表字段改名      |     无需修改     |      需要修改       |
|        可读性        |        低        |         高          |
| 是否可以建立索引优化 |        否        |         是          |

## 11.2. varchar/char区别

(1) 定长/变长：是否由实际存储内容决定

char是定长字段，假如申请了char(10)的空间,那么无论实际存储多少内容.该 字段都占用
10 个字符

varchar是变长的,也就是说申请的只是最大长度,占用
的空间为实际字符长度+1,最后一个字符存储使用了多长的空间.

(2) char查询效率更快
